{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Practice problem!  yay\n",
    "#\n",
    "# Our mission, should we choose to accept it, is to see if we can use supervised machine learning to train\n",
    "# a deep neural network to count the number of vowels in words it has never seen before, without ever telling\n",
    "# neural network which letters are vowels!\n",
    "#\n",
    "# This is best done algorithmically with a few lines of code and no neural networks\n",
    "# but that doesn't matter - it's a practice problem and anything goes :)  \n",
    "# Also, we only count a,e,i,o,u as vowels (sorry about that y, nothing personal).\n",
    "#\n",
    "# The data set consists of just over 10k words in random order.  Each word has a maximum of 10 characters.\n",
    "# The first row is the header, and there are five columns (the first is the row index):\n",
    "#\n",
    "#   1st column:         - the row index\n",
    "#   2nd column:  a2i    - the word, in english\n",
    "#   3rd column:  vowels - the number of vowels in the word\n",
    "#   4th column:  binary - the word, encoded into 70 binary digits, left-padded with 0, with 7 bits per character.\n",
    "#                         For example, the word 'vital' is \n",
    "#                         encoded as 0000000000000000000000000000000000011101101101001111010011000011101100\n",
    "#\n",
    "\n",
    "\n",
    "# Special thanks to the UCI Machine Learning Repository who provided the data set that this one was based on\n",
    "# For similar datasets, please see https://archive.ics.uci.edu/ml/datasets/bag+of+words\n",
    "# Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12418, 2)\n",
      "['a2i' 'vowels']\n",
      "(10916, 2)\n"
     ]
    }
   ],
   "source": [
    "# This cell is used to generate the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('vocab.nips.txt')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def countVowels(row):\n",
    "    s = row['a2i']\n",
    "    return s.count('a') + s.count('e') + s.count('i') + s.count('o') + s.count('u')\n",
    "\n",
    "\n",
    "df['vowels'] = df.apply(countVowels, axis=1)\n",
    "print(df.shape)\n",
    "print(df.columns.values)\n",
    "df = df[df.a2i.str.len() <= 10]\n",
    "print(df.shape)\n",
    "\n",
    "df['binary'] = df.apply(lambda row: ''.join(format(ord(x), 'b') for x in row[0]).rjust(70, '0'), axis=1)\n",
    "df.to_csv('vocab.vowels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows:    10916\n",
      "Training rows: 7641\n"
     ]
    }
   ],
   "source": [
    "# This cell loads the data set and splits it into numpy arrays of labels and examples, \n",
    "# for both training and evalutation.\n",
    "\n",
    "# The train_data, and train_labels are used for training the neural net.  The train_words is just there for convenience.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('vocab.vowels.txt', names=['id', 'word', 'vowels', 'binary'], index_col='id', skiprows=1)\n",
    "rows = df.shape[0]\n",
    "train_rows = int(rows * 0.7)\n",
    "print(\"Total rows:    \" + str(rows))\n",
    "print(\"Training rows: \" + str(train_rows))\n",
    "\n",
    "df_train, df_eval = df.iloc[:train_rows, :], df.iloc[train_rows:, :]\n",
    "\n",
    "train_list = []\n",
    "eval_list = []\n",
    "\n",
    "for i in df_train['binary']:\n",
    "    train_list.append([int(c) for c in i])\n",
    "\n",
    "for i in df_eval['binary']:\n",
    "    eval_list.append([int(c) for c in i])\n",
    "\n",
    "\n",
    "train_data = np.array(train_list).astype(np.float32)\n",
    "eval_data  = np.array(eval_list).astype(np.float32)\n",
    "train_words = df_train.iloc[:,0].values\n",
    "eval_words = df_eval.iloc[:,0].values\n",
    "train_labels = df_train.iloc[:,1].values.astype(np.float32)\n",
    "eval_labels = df_eval.iloc[:,1].values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account\n",
      "3.0\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.\n",
      "  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.\n",
      "  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's just print some example data\n",
    "i = 5432\n",
    "print(train_words[i])\n",
    "print(train_labels[i])\n",
    "print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "idx = 0 # The layer index\n",
    "dropout_rate = 0.5\n",
    "model_dir = \"results\"\n",
    "\n",
    "def normalize(mode, input):\n",
    "    return tf.layers.batch_normalization(input, training=True)\n",
    "\n",
    "def convolution(mode, input_layer, filters, kernel_size, padding=\"VALID\"):\n",
    "    global idx\n",
    "    idx = idx+1\n",
    "    print(\"Layer: conv\" + str(idx))\n",
    "    \n",
    "    return normalize(mode, tf.layers.separable_conv2d(\n",
    "          name=\"conv\" + str(idx) + \"_\",\n",
    "          inputs=input_layer,\n",
    "          filters=filters,\n",
    "          kernel_size=kernel_size,\n",
    "          padding=padding,\n",
    "          activation=tf.nn.relu))\n",
    "                     \n",
    "def pool(mode, input_layer, pool_size=[2,2], strides=[2,2]):\n",
    "    global idx\n",
    "    idx = idx+1\n",
    "    print(\"Layer: pool\" + str(idx) + \"_\")\n",
    "    \n",
    "    return tf.layers.max_pooling2d(inputs=input_layer, pool_size=pool_size, strides=strides, name=\"pool\" + str(idx))\n",
    "\n",
    "def deep(mode, layer, units, reshape=None):\n",
    "    global idx\n",
    "    idx = idx+1\n",
    "    print(\"Layer: deep\" + str(idx) + \"_\")\n",
    "    \n",
    "    if reshape != None:\n",
    "        layer = tf.reshape(layer, reshape)\n",
    "#     layer = tf.layers.dropout(inputs=layer, rate=dropout_rate, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    layer = tf.layers.dense(inputs=layer, units=units, activation=tf.nn.relu)\n",
    "    layer = tf.layers.batch_normalization(layer, training=True)\n",
    "    return layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                     \n",
    "def model_fn(features, labels, mode):\n",
    "    \"\"\"Neural Network Model.\"\"\"\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "\n",
    "        # Input Layer\n",
    "        initial = tf.reshape(features[\"x\"], [-1, 70])\n",
    "        num_outputs = 11\n",
    "\n",
    "        layer = initial\n",
    "        \n",
    "        k  = [64, 64, 64, 64]\n",
    "\n",
    "        # Convolutional layers\n",
    "        layer = deep(mode, layer, k[0])\n",
    "        layer = deep(mode, layer, k[1])\n",
    "        layer = deep(mode, layer, k[2])\n",
    "        layer = deep(mode, layer, k[3])\n",
    "        \n",
    "        \n",
    "        # Logits Layer (there are 11 possible outputs)\n",
    "        logits = tf.layers.dense(inputs=layer, units=num_outputs, name=\"last_layer\")\n",
    "\n",
    "        predictions = {\n",
    "          # Generate predictions (for PREDICT and EVAL mode)\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=num_outputs)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        tf.summary.merge_all()\n",
    "        \n",
    "        # Configure the Training Op (for TRAIN mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer()\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        \n",
    "        \n",
    "        eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss=loss, \n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll use this to perform the training\n",
    "\n",
    "def trainTheModel(train_data, train_labels, eval_data, eval_labels):\n",
    "    global idx\n",
    "    # Create the Estimator\n",
    "    session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "    session_config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig()\n",
    "    run_config = run_config.replace(\n",
    "        save_checkpoints_steps=100, \n",
    "        session_config=session_config,\n",
    "        keep_checkpoint_max=100)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn, model_dir=model_dir, config=run_config)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    summary_hook = tf.train.SummarySaverHook(\n",
    "        100,\n",
    "        output_dir=model_dir,\n",
    "        scaffold=tf.train.Scaffold())\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        # train\n",
    "        idx=0\n",
    "        estimator.train(\n",
    "            input_fn=train_input_fn,\n",
    "            steps=500, hooks=[summary_hook])\n",
    "        tf.reset_default_graph()\n",
    "        idx=0\n",
    "        estimator.evaluate(input_fn=eval_input_fn, steps=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 100, '_save_checkpoints_steps': 100, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.75\n",
      "}\n",
      "allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_log_step_count_steps': 100, '_tf_random_seed': 1, '_model_dir': 'results'}\n",
      "Layer: deep1_\n",
      "Layer: deep2_\n",
      "Layer: deep3_\n",
      "Layer: deep4_\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into results/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.99027, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 101 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 48.5515\n",
      "INFO:tensorflow:loss = 1.06912, step = 101 (2.061 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 201 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 47.5223\n",
      "INFO:tensorflow:loss = 0.880977, step = 201 (2.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 301 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 51.7321\n",
      "INFO:tensorflow:loss = 0.720613, step = 301 (1.933 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 401 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 49.1249\n",
      "INFO:tensorflow:loss = 0.647798, step = 401 (2.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into results/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.645041.\n",
      "Layer: deep1_\n",
      "Layer: deep2_\n",
      "Layer: deep3_\n",
      "Layer: deep4_\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-28-22:10:46\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-500\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-28-22:10:47\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.707, global_step = 500, loss = 0.783172\n",
      "Layer: deep1_\n",
      "Layer: deep2_\n",
      "Layer: deep3_\n",
      "Layer: deep4_\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-500\n",
      "INFO:tensorflow:Saving checkpoints for 501 into results/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.397069, step = 501\n",
      "INFO:tensorflow:Saving checkpoints for 601 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 46.8838\n",
      "INFO:tensorflow:loss = 0.4992, step = 601 (2.134 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 701 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 44.7377\n",
      "INFO:tensorflow:loss = 0.442423, step = 701 (2.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 801 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 47.1449\n",
      "INFO:tensorflow:loss = 0.38854, step = 801 (2.121 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 901 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 47.7179\n",
      "INFO:tensorflow:loss = 0.42475, step = 901 (2.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into results/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.40664.\n",
      "Layer: deep1_\n",
      "Layer: deep2_\n",
      "Layer: deep3_\n",
      "Layer: deep4_\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-28-22:11:09\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-1000\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-28-22:11:10\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.736, global_step = 1000, loss = 0.73606\n",
      "Layer: deep1_\n",
      "Layer: deep2_\n",
      "Layer: deep3_\n",
      "Layer: deep4_\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from results/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into results/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.217567, step = 1001\n",
      "INFO:tensorflow:Saving checkpoints for 1101 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 44.6863\n",
      "INFO:tensorflow:loss = 0.425415, step = 1101 (2.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1201 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 50.4113\n",
      "INFO:tensorflow:loss = 0.277151, step = 1201 (1.984 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1301 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 44.3972\n",
      "INFO:tensorflow:loss = 0.281258, step = 1301 (2.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1401 into results/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 46.3643\n",
      "INFO:tensorflow:loss = 0.373853, step = 1401 (2.157 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-aec3b87b6442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainTheModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-03944ac9af22>\u001b[0m in \u001b[0;36mtrainTheModel\u001b[0;34m(train_data, train_labels, eval_data, eval_labels)\u001b[0m\n\u001b[1;32m     41\u001b[0m         estimator.train(\n\u001b[1;32m     42\u001b[0m             \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             steps=500, hooks=[summary_hook])\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clearwhale/anaconda/envs/example/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the training \n",
    "trainTheModel(train_data, train_labels, eval_data, eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

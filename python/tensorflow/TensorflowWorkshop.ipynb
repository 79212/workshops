{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflowâ„¢ Workshop\n",
    "\n",
    "# Portions of this page are modifications based on work created and shared by Google \n",
    "# and used according to terms described in the Creative Commons 3.0 Attribution License.\n",
    "# \n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py\n",
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "\n",
    "\n",
    "# Is this an Open Source workshop?  Yes!\n",
    "# ==============================================================================\n",
    "# Copyright 2017 Toronto AI. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('.',one_hot=True)\n",
    "\n",
    "print(mnist)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"  training set: \", mnist.train.images.shape)\n",
    "print(\"validation set: \", mnist.validation.images.shape)\n",
    "print(\"      test set: \", mnist.test.images.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the training samples\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "fig = plot.figure(figsize=(28,28)) \n",
    "plot.axis('off')\n",
    "count = 16\n",
    "for i in range(count):\n",
    "    fig.add_subplot(plot.subplot(2,count,i+1))\n",
    "    plot.imshow(mnist.train.images[i].reshape(28,28))\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "plot.axis('off')\n",
    "\n",
    "def show_image(plot, ndarray_of_pixels, size=(28,28), cmap='viridis'):\n",
    "    plot.imshow(ndarray_of_pixels.reshape(*size), cmap=cmap)\n",
    "    time.sleep(0.1)\n",
    "    clear_output(True)\n",
    "    plot.show()\n",
    "\n",
    "# Let's preview some of the training data\n",
    "count = 40\n",
    "for i in range(count):\n",
    "    show_image(plot, mnist.train.images[i])\n",
    "plot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "def visualize(images, cmap='viridis'):\n",
    "    trainedWeights = []\n",
    "    for i in range(10):\n",
    "        trainedWeights.append(images[i,:,:])\n",
    "        plot.subplot(2,5,i+1)\n",
    "        plot.axis('off')\n",
    "        plot.imshow(trainedWeights[i], cmap=cmap, interpolation='none')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()         # Allows us to re-run this cell\n",
    "\n",
    "with tf.name_scope('ai_inputs'):\n",
    "    # samples_x will hold our training samples\n",
    "    samples_x  = tf.placeholder(tf.float32, [None, 784], name='samples')\n",
    "\n",
    "    # labels_y holds the one_hot labels of the handwritten digits in an array\n",
    "    labels_y  = tf.placeholder(tf.float32, [None, 10], name='labels')\n",
    "\n",
    "\n",
    "with tf.name_scope('ai_model'):\n",
    "    # Our model will contain 10 separate interal 'ideas' or 'representations' of what \n",
    "    # each digit looks like.  These 'ideas' are represented by 784 weights that are applied \n",
    "    # to each input pixel to later score how closely a new handwritten digit compares \n",
    "    # with the 'ideal' digit it has learned.  Our model also includes another form of weight called \n",
    "    # a 'bias' that will adjust the weighted value by a constant amount, regardless of the input.\n",
    "\n",
    "    # Both the weights and the biases are learned values that will be learned when the model \n",
    "    # is trained againstthe training set.\n",
    "    weights_w = tf.Variable(tf.zeros([784, 10]), name=\"weights\")\n",
    "    biases_b  = tf.Variable(tf.zeros([10]), name=\"biases\")\n",
    "\n",
    "    # Our model is linear y = x*W + b\n",
    "    # It has 10 cells, representing the 10 output neurons\n",
    "    # The output is formed by\n",
    "    model_y   = tf.matmul(samples_x, weights_w) + biases_b\n",
    "\n",
    "\n",
    "with tf.name_scope('ai_cost_function'):\n",
    "    cost_function = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(labels=labels_y, logits=model_y))\n",
    "\n",
    "\n",
    "with tf.name_scope('ai_optimizer'):\n",
    "    # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "    # outputs of 'y', and then average across the batch.\n",
    "    train_step = tf.train.GradientDescentOptimizer(.1).minimize(cost_function)\n",
    "\n",
    "with tf.name_scope('ai_visualization'):\n",
    "    # This tensor will be used to display the weights as an image on screen.\n",
    "    reshapedWeights = tf.reshape(tf.transpose(tf.slice(weights_w, [0,0], [784,10])), [10,28,28])\n",
    "\n",
    "\n",
    "# Log the model's graph so we can visualize it in TensorBoard\n",
    "writer = tf.summary.FileWriter('/tmp/torontoai/digit-model', cost_function.graph)\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 8.0)\n",
    "\n",
    "# Train\n",
    "numRounds = 100  # Try adjusting the number of training rounds.\n",
    "for i in range(numRounds):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(2)    # Try adjusting the batch size.\n",
    "    results = sess.run([train_step, reshapedWeights], feed_dict={samples_x: batch_xs, labels_y: batch_ys})\n",
    "    \n",
    "    # Visualize it!\n",
    "    x = 1\n",
    "    if i % x == 0 and (i < 25):\n",
    "        print(reshapedWeights)\n",
    "        visualize(results[1], cmap='plasma')\n",
    "        clear_output(True) if i + x < numRounds else 0\n",
    "        plot.show()\n",
    "        plot.close()\n",
    "\n",
    "\n",
    "clear_output(True)\n",
    "visualize(results[1], cmap='plasma')\n",
    "print('Training complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How did the training go?  Let's check the accurracy\n",
    "correct_prediction = tf.equal(tf.argmax(model_y, 1), tf.argmax(labels_y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accurracy: \", sess.run(accuracy, feed_dict={samples_x: mnist.test.images,\n",
    "                                  labels_y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the trained weights for the handwritten digit 8\n",
    "trainedWeights = tf.transpose(tf.slice(weights_w, [0,8], [784,1])).eval().reshape(28,28)\n",
    "show_image(plot, trainedWeights, cmap='viridis')\n",
    "\n",
    "# The trained bias is displayed below the image of the weights\n",
    "trainedBias = biases_b.eval()[8]\n",
    "print(trainedBias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Okay, now let's visualize all of the trained weights\n",
    "\n",
    "plot.figure(figsize=(15, 6), dpi=160)\n",
    "for i in range(10):\n",
    "    plot.subplot(2,5,i+1)\n",
    "    plot.axis('off')\n",
    "    trainedWeights = tf.transpose(tf.slice(weights_w, [0,i], [784,1])).eval().reshape(28,28)\n",
    "    plot.imshow(trainedWeights, cmap='plasma')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets('.',one_hot=True)  #reload\n",
    "sample = mnist.train.images[485]\n",
    "weights = tf.slice(weights_w, [0,0], [784,10]).eval().transpose()\n",
    "costs = np.add(np.matmul(weights,sample), biases_b.eval())\n",
    "show_image(plot, sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the evidence gathered through the model for each possible digit 0-9\n",
    "show_image(plot, costs, size=(10,1))\n",
    "print(costs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply softmax to turn the evidence into a probability distribution\n",
    "# In softmax, additional evidence multiplies the probability, resulting in a clear signal for the digit 8\n",
    "softmax_costs = tf.nn.softmax(tf.constant(costs)).eval()\n",
    "show_image(plot, softmax_costs, size=(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
